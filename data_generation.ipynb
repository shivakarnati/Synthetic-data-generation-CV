{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade diffusers[torch]\n",
    "#%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create image generation pipeline ###\n",
    "\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "pipeline.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate images ###\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('/content/faces/happy', exist_ok=True)\n",
    "os.makedirs('/content/faces/sad', exist_ok=True)\n",
    "os.makedirs('/content/faces/angry', exist_ok=True)\n",
    "os.makedirs('/content/faces/surprised', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicities = ['a latino', 'a white', 'a black', 'a middle eastern', 'an indian', 'an asian']\n",
    "\n",
    "genders = ['male', 'female']\n",
    "\n",
    "emotion_prompts = {'happy': 'smiling',\n",
    "                   'sad': 'frowning, sad face expression, crying',\n",
    "                   'surprised': 'surprised, opened mouth, raised eyebrows',\n",
    "                   'angry': 'angry'}\n",
    "\n",
    "\n",
    "for j in range(250):\n",
    "\n",
    "  for emotion in emotion_prompts.keys():\n",
    "\n",
    "    emotion_prompt = emotion_prompts[emotion]\n",
    "\n",
    "    ethnicity = random.choice(ethnicities)\n",
    "    gender = random.choice(genders)\n",
    "\n",
    "    # print(emotion, ethnicity, gender)\n",
    "\n",
    "    prompt = 'Medium-shot portrait of {} {}, {}, front view, looking at the camera, color photography, '.format(ethnicity, gender, emotion_prompt) + \\\n",
    "            'photorealistic, hyperrealistic, realistic, incredibly detailed, crisp focus, digital art, depth of field, 50mm, 8k'\n",
    "    negative_prompt = '3d, cartoon, anime, sketches, (worst quality:2), (low quality:2), (normal quality:2), lowres, normal quality, ((monochrome)), ' + \\\n",
    "                      '((grayscale)) Low Quality, Worst Quality, plastic, fake, disfigured, deformed, blurry, bad anatomy, blurred, watermark, grainy, signature'\n",
    "\n",
    "    img = pipeline(prompt, negative_prompt=negative_prompt).images[0]\n",
    "\n",
    "    img.save('/content/faces/{}/{}.png'.format(emotion, str(j).zfill(4)))\n",
    "\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%zip -r faces.zip /faces"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
